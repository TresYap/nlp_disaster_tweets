{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.57034\n",
       "1    0.42966\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for class balance\n",
    "train.target.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2256</th>\n",
       "      <td>3235</td>\n",
       "      <td>deluged</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Businesses are deluged with inroices.|Make you...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>2500</td>\n",
       "      <td>collided</td>\n",
       "      <td>Nairobi, Kenya</td>\n",
       "      <td>Stepkans Media - Two confirmed dead after the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>1017</td>\n",
       "      <td>blazing</td>\n",
       "      <td>Konoha</td>\n",
       "      <td>@__srajapakse__ Why thank you there missy ?? t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>180</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>304</td>\n",
       "      <td>Sometimes you face difficulties not because yo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2326</th>\n",
       "      <td>3342</td>\n",
       "      <td>demolished</td>\n",
       "      <td>Catalonia, Spain</td>\n",
       "      <td>Demolished My Personal Best  http://t.co/ImULL...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2060</th>\n",
       "      <td>2954</td>\n",
       "      <td>dead</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>17 dead as Afghanistan aircraft crashes: An Af...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4341</th>\n",
       "      <td>6165</td>\n",
       "      <td>hijack</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Swansea Û÷plot hijack transfer move for South...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7125</th>\n",
       "      <td>10207</td>\n",
       "      <td>violent%20storm</td>\n",
       "      <td>3rd Eye Chakra</td>\n",
       "      <td>Violent video: Ukraine rioters brutally beat p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>2864</td>\n",
       "      <td>damage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>It's crazy how a phone can do so much damage t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721</th>\n",
       "      <td>2483</td>\n",
       "      <td>collided</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>SSP East says a car AEG 061 driven by a young ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id          keyword          location  \\\n",
       "2256   3235          deluged               NaN   \n",
       "1736   2500         collided    Nairobi, Kenya   \n",
       "704    1017          blazing            Konoha   \n",
       "125     180       aftershock               304   \n",
       "2326   3342       demolished  Catalonia, Spain   \n",
       "2060   2954             dead       Afghanistan   \n",
       "4341   6165           hijack               NaN   \n",
       "7125  10207  violent%20storm    3rd Eye Chakra   \n",
       "1991   2864           damage               NaN   \n",
       "1721   2483         collided          Pakistan   \n",
       "\n",
       "                                                   text  target  \n",
       "2256  Businesses are deluged with inroices.|Make you...       0  \n",
       "1736  Stepkans Media - Two confirmed dead after the ...       1  \n",
       "704   @__srajapakse__ Why thank you there missy ?? t...       0  \n",
       "125   Sometimes you face difficulties not because yo...       0  \n",
       "2326  Demolished My Personal Best  http://t.co/ImULL...       0  \n",
       "2060  17 dead as Afghanistan aircraft crashes: An Af...       1  \n",
       "4341  Swansea Û÷plot hijack transfer move for South...       1  \n",
       "7125  Violent video: Ukraine rioters brutally beat p...       1  \n",
       "1991  It's crazy how a phone can do so much damage t...       0  \n",
       "1721  SSP East says a car AEG 061 driven by a young ...       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.keyword.notnull()].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Targets that have Null Keyword\n",
      "0.004375863657300783\n",
      "0.012840110058086213\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of Targets that have Null Keyword\")\n",
    "print(train[train.target == 0].keyword.isna().sum()/train[train.target == 0].shape[0])\n",
    "print(train[train.target == 1].keyword.isna().sum()/train[train.target == 1].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Targets that have Null Locatoin\n",
      "0.33578995854444954\n",
      "0.32864567410577805\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of Targets that have Null Locatoin\")\n",
    "print(train[train.target == 0].location.isna().sum()/train[train.target == 0].shape[0])\n",
    "print(train[train.target == 1].location.isna().sum()/train[train.target == 1].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Keyword for now, because a keyword is present in text technically\n",
    "### Drop Location because I want the model to learn based on text content, and not location yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "Text preprocessing functions from geeksforgeeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop keyword and Location\n",
    "try:\n",
    "    train = train.drop(['keyword', 'location'], axis=1)\n",
    "except:\n",
    "    print(\"columns already dropped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lowercase \n",
    "train.text = train.text.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "# From geeksforgeeks.org\n",
    "# remove punctuation \n",
    "def remove_punctuation(text): \n",
    "    translator = str.maketrans('', '', string.punctuation) \n",
    "    return text.translate(translator) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#raining #flooding #florida #tampabay #tampa 18 or 19 days. i've lost count \""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.text.iloc[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean = train\n",
    "train_clean.text = train_clean.text.apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'raining flooding florida tampabay tampa 18 or 19 days ive lost count '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.text.iloc[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'raining flooding florida tampabay tampa 18 or 19 days ive lost count '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_clean.text.iloc[12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Numbers from text, but might inflect instead\n",
    "Rationale: Don't want to cheat (ex. multiple tweets about an earthquake that lasted 10 days) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' people receive wildfires evacuation orders in california '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove Numbers\n",
    "def remove_numbers(text): \n",
    "    result = re.sub(r'\\d+', '', text) \n",
    "    return result \n",
    "  \n",
    "input_str = \"13000 people receive wildfires evacuation orders in california \"\n",
    "remove_numbers(input_str) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'raining flooding florida tampabay tampa 18  19 days ive lost count '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove English Stopwords\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "def remove_stopwords(text): \n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    re_stop_words = re.compile(r\"\\b(\" + \"|\".join(stop_words) + \")\\\\W\", re.I)\n",
    "    filtered_text =  re_stop_words.sub(\" \", text)\n",
    "    return filtered_text \n",
    "  \n",
    "example_text = \"raining flooding florida tampabay tampa 18 or 19 days ive lost count \"\n",
    "remove_stopwords(example_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rain flood florida tampabay tampa 18 or 19 day ive lost count'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stemmer\n",
    "from nltk.stem.porter import PorterStemmer \n",
    "stemmer = PorterStemmer() \n",
    "  \n",
    "# stem words in the list of tokenised words \n",
    "def stem_words(text): \n",
    "    stems = [stemmer.stem(word) for word in text.split()] \n",
    "    return \" \".join(stems)\n",
    "  \n",
    "text = \"raining flooding florida tampabay tampa 18 or 19 days ive lost count \"\n",
    "stem_words(text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    try:\n",
    "        df.drop(['keyword', 'location'], axis=1, inplace=True)\n",
    "    except:\n",
    "        print(\"columns already dropped\")\n",
    "    df.text = df.text.apply(remove_punctuation)\n",
    "    df.text = df.text.apply(remove_numbers)\n",
    "    df.text = df.text.apply(remove_stopwords)\n",
    "    df.text = df.text.apply(stem_words)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns already dropped\n"
     ]
    }
   ],
   "source": [
    "train_clean = preprocess(train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>deed reason earthquak may allah forgiv us all</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>forest fire near la rong sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>resid ask shelter place notifi offic evacu she...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>peopl receiv wildfir evacu order california</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>got sent photo rubi alaska smoke wildfir pour ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>rockyfir updat california hwi close direct due...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>flood disast heavi rain caus flash flood stree...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "      <td>im top hill see fire wood</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>there emerg evacu happen build across street</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>im afraid tornado come area</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16</td>\n",
       "      <td>three peopl die heat wave far</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17</td>\n",
       "      <td>haha south tampa get flood hah wait second liv...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18</td>\n",
       "      <td>rain flood florida tampabay tampa day ive lost...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>19</td>\n",
       "      <td>flood bago myanmar arriv bago</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20</td>\n",
       "      <td>damag school bu multi car crash break</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>23</td>\n",
       "      <td>what man</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>24</td>\n",
       "      <td>love fruit</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>25</td>\n",
       "      <td>summer love</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>26</td>\n",
       "      <td>car fast</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>28</td>\n",
       "      <td>goooooooaaaaaal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>31</td>\n",
       "      <td>ridicul</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>32</td>\n",
       "      <td>london cool</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>33</td>\n",
       "      <td>love ski</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>34</td>\n",
       "      <td>wonder day</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>36</td>\n",
       "      <td>looooool</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>37</td>\n",
       "      <td>wayi cant eat shit</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>38</td>\n",
       "      <td>nyc last week</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>39</td>\n",
       "      <td>love girlfriend</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>40</td>\n",
       "      <td>cooool</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>41</td>\n",
       "      <td>like pasta</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7583</th>\n",
       "      <td>10835</td>\n",
       "      <td>pic yr old pkk suicid bomber deton bomb turkey...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7584</th>\n",
       "      <td>10837</td>\n",
       "      <td>box readi explod explod kitten final arriv gam...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7585</th>\n",
       "      <td>10839</td>\n",
       "      <td>calgari polic flood road closur calgari httptc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7586</th>\n",
       "      <td>10840</td>\n",
       "      <td>sismo detectado japìn seismic intens iwat miya...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7587</th>\n",
       "      <td>10841</td>\n",
       "      <td>siren everywher</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7588</th>\n",
       "      <td>10842</td>\n",
       "      <td>break isi claim respons mosqu attack saudi ara...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7589</th>\n",
       "      <td>10843</td>\n",
       "      <td>omg earthquak</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7590</th>\n",
       "      <td>10844</td>\n",
       "      <td>sever weather bulletin typhoon ûïhannaphû s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7591</th>\n",
       "      <td>10846</td>\n",
       "      <td>heat wave warn aa ayyo dei plan visit friend year</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7592</th>\n",
       "      <td>10847</td>\n",
       "      <td>group suicid bomber deton explosivespack vest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7593</th>\n",
       "      <td>10848</td>\n",
       "      <td>heard realli loud bang everyon asleep great</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7594</th>\n",
       "      <td>10849</td>\n",
       "      <td>ga thing explod heard scream whole street smel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7595</th>\n",
       "      <td>10850</td>\n",
       "      <td>nw flash flood warn continu shelbi counti pm w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7596</th>\n",
       "      <td>10851</td>\n",
       "      <td>rt livingsaf nw issu sever thunderstorm warn p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7597</th>\n",
       "      <td>10852</td>\n",
       "      <td>mh aircraft debri found la reunion miss malays...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7598</th>\n",
       "      <td>10853</td>\n",
       "      <td>fatherofthre lost control car overtak collid b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7599</th>\n",
       "      <td>10854</td>\n",
       "      <td>earthquak km ssw anza california iphon user do...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7600</th>\n",
       "      <td>10855</td>\n",
       "      <td>evacu order lift town roosevelt httptcoedyfoep...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7601</th>\n",
       "      <td>10859</td>\n",
       "      <td>break la refugio oil spill may costlier bigger...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7602</th>\n",
       "      <td>10860</td>\n",
       "      <td>siren went wasnt forney tornado warn</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7603</th>\n",
       "      <td>10862</td>\n",
       "      <td>offici say quarantin place alabama home possib...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7604</th>\n",
       "      <td>10863</td>\n",
       "      <td>worldnew fallen powerlin glink tram updat fire...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7605</th>\n",
       "      <td>10864</td>\n",
       "      <td>flip side im walmart bomb everyon evacu stay t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7606</th>\n",
       "      <td>10866</td>\n",
       "      <td>suicid bomber kill saudi secur site mosqu reut...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7607</th>\n",
       "      <td>10867</td>\n",
       "      <td>stormchas violent record break ef el reno okla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>two giant crane hold bridg collaps nearbi home...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>ariaahrari thetawniest control wild fire calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>utckm volcano hawaii httptcozdtoydebj</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>polic investig ebik collid car littl portug eb...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>latest home raze northern california wildfir a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  target\n",
       "0         1      deed reason earthquak may allah forgiv us all       1\n",
       "1         4               forest fire near la rong sask canada       1\n",
       "2         5  resid ask shelter place notifi offic evacu she...       1\n",
       "3         6        peopl receiv wildfir evacu order california       1\n",
       "4         7  got sent photo rubi alaska smoke wildfir pour ...       1\n",
       "5         8  rockyfir updat california hwi close direct due...       1\n",
       "6        10  flood disast heavi rain caus flash flood stree...       1\n",
       "7        13                          im top hill see fire wood       1\n",
       "8        14       there emerg evacu happen build across street       1\n",
       "9        15                        im afraid tornado come area       1\n",
       "10       16                      three peopl die heat wave far       1\n",
       "11       17  haha south tampa get flood hah wait second liv...       1\n",
       "12       18  rain flood florida tampabay tampa day ive lost...       1\n",
       "13       19                      flood bago myanmar arriv bago       1\n",
       "14       20              damag school bu multi car crash break       1\n",
       "15       23                                           what man       0\n",
       "16       24                                         love fruit       0\n",
       "17       25                                        summer love       0\n",
       "18       26                                           car fast       0\n",
       "19       28                                    goooooooaaaaaal       0\n",
       "20       31                                            ridicul       0\n",
       "21       32                                        london cool       0\n",
       "22       33                                           love ski       0\n",
       "23       34                                         wonder day       0\n",
       "24       36                                           looooool       0\n",
       "25       37                                 wayi cant eat shit       0\n",
       "26       38                                      nyc last week       0\n",
       "27       39                                    love girlfriend       0\n",
       "28       40                                             cooool       0\n",
       "29       41                                         like pasta       0\n",
       "...     ...                                                ...     ...\n",
       "7583  10835  pic yr old pkk suicid bomber deton bomb turkey...       1\n",
       "7584  10837  box readi explod explod kitten final arriv gam...       0\n",
       "7585  10839  calgari polic flood road closur calgari httptc...       1\n",
       "7586  10840  sismo detectado japìn seismic intens iwat miya...       1\n",
       "7587  10841                                    siren everywher       0\n",
       "7588  10842  break isi claim respons mosqu attack saudi ara...       1\n",
       "7589  10843                                      omg earthquak       1\n",
       "7590  10844  sever weather bulletin typhoon ûïhannaphû s...       1\n",
       "7591  10846  heat wave warn aa ayyo dei plan visit friend year       1\n",
       "7592  10847  group suicid bomber deton explosivespack vest ...       1\n",
       "7593  10848        heard realli loud bang everyon asleep great       0\n",
       "7594  10849  ga thing explod heard scream whole street smel...       1\n",
       "7595  10850  nw flash flood warn continu shelbi counti pm w...       1\n",
       "7596  10851  rt livingsaf nw issu sever thunderstorm warn p...       1\n",
       "7597  10852  mh aircraft debri found la reunion miss malays...       1\n",
       "7598  10853  fatherofthre lost control car overtak collid b...       1\n",
       "7599  10854  earthquak km ssw anza california iphon user do...       1\n",
       "7600  10855  evacu order lift town roosevelt httptcoedyfoep...       1\n",
       "7601  10859  break la refugio oil spill may costlier bigger...       1\n",
       "7602  10860               siren went wasnt forney tornado warn       1\n",
       "7603  10862  offici say quarantin place alabama home possib...       1\n",
       "7604  10863  worldnew fallen powerlin glink tram updat fire...       1\n",
       "7605  10864  flip side im walmart bomb everyon evacu stay t...       1\n",
       "7606  10866  suicid bomber kill saudi secur site mosqu reut...       1\n",
       "7607  10867  stormchas violent record break ef el reno okla...       1\n",
       "7608  10869  two giant crane hold bridg collaps nearbi home...       1\n",
       "7609  10870  ariaahrari thetawniest control wild fire calif...       1\n",
       "7610  10871              utckm volcano hawaii httptcozdtoydebj       1\n",
       "7611  10872  polic investig ebik collid car littl portug eb...       1\n",
       "7612  10873  latest home raze northern california wildfir a...       1\n",
       "\n",
       "[7613 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2), strip_accents=\"unicode\")\n",
    "feature_matrix = tfidf.fit_transform(train_clean.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pd.DataFrame(feature_matrix.toarray(), columns=tfidf.get_feature_names())\n",
    "train_y = train.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note to self: Remove weird letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split train validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_x, train_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearSVC()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7272727272727273"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_val, pred_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "test = preprocess(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feature_matrix = tfidf.transform(test.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(test_feature_matrix.toarray(), columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
